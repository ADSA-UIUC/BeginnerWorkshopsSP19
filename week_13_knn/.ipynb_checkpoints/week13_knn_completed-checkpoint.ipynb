{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zzjo_SgHBOP"
   },
   "source": [
    "![ADSA Logo](http://i.imgur.com/BV0CdHZ.png?2 \"ADSA Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YcoxYyNHFkG"
   },
   "source": [
    "# Fall 2018 ADSA Workshop - K Nearest Neighbors From Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8An3vBZHufY"
   },
   "source": [
    "## [k-Nearest Neighbors][knn] (K-NN)\n",
    "\n",
    "Fundamentally, this algorithm is\n",
    "remarkable simple and is based on the principle that data values in an\n",
    "$N$- dimensional space are generally located near other similar objects.\n",
    "The number of nearest neighbors, k, is a tuning parameter, and can be\n",
    "specified a priori or in some algorithms empirically determined. The\n",
    "basic principle behind k-nn is demonstrated in the following figure from\n",
    "Wikipedia:\n",
    "\n",
    "![knn Image from Wikipedia][knni]\n",
    "\n",
    "As shown in the image, when a new datum is added, the classification\n",
    "must be assigned. In the case of k-nn, this is done by looking at the\n",
    "nearest neighbors and using some statistical evaluation of their\n",
    "classes. For example, we could use some weighted combination of the\n",
    "nearest neighbors, where the weight might be determined by the relative\n",
    "distance of each neighbor from the datum of interest. \n",
    "\n",
    "In the following code cells, we demonstrate how to perform knn\n",
    "classification by using scikit-learn. In this example, we use five\n",
    "nearest neighbors (but this value can be easily adjusted to see how the\n",
    "classification performance changes). The standard classification\n",
    "process in scikit-learn is to first fit a model to the training data\n",
    "and to subsequently apply this model to predict values for the testing\n",
    "data. After this process, we first compute the prediction score before\n",
    "displaying the confusion matrix for this algorithm.\n",
    "\n",
    "-----\n",
    "\n",
    "[knn]: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "[knni]: https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/500px-KnnClassification.svg.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zf2lKDtfKQdR"
   },
   "source": [
    "##This workshop will be broken down into six steps\n",
    "1. Handle Data: Open the dataset from CSV and split into test/train datasets.\n",
    "2. Similarity: Calculate the distance between two data instances.\n",
    "3. Neighbors: Locate k most similar data instances.\n",
    "4. Response: Generate a response from a set of data instances.\n",
    "5. Accuracy: Summarize the accuracy of predictions.\n",
    "6. Main: Tie it all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYZU2rjPIXRP"
   },
   "source": [
    "##1. Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5lj64fIHKlW"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "gYdhDJJfJijZ",
    "outputId": "d109ea1a-4ac7-4f35-8c83-c4a4220060e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of iris_dataset: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys of iris_dataset: {}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE5xvrb2IhMh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "l13ltiJWIu8t",
    "outputId": "20508f72-2145-418d-e0b4-eefe8f127e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      "[[6.4 3.1 5.5 1.8]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.2]]\n",
      "(120, 4)\n",
      "\n",
      "y_train: \n",
      "[2 1 0 2 2]\n",
      "(120,)\n",
      "\n",
      "X_test: \n",
      "[[5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.  3.4 1.5 0.2]]\n",
      "(30, 4)\n",
      "\n",
      "y_test: \n",
      "[2 1 0 2 0]\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ')\n",
    "print(X_train[0:5])\n",
    "print(X_train.shape)\n",
    "print()\n",
    "print('y_train: ')\n",
    "print(y_train[0:5])\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print('X_test: ')\n",
    "print(X_test[0:5])\n",
    "print(X_test.shape)\n",
    "print()\n",
    "print('y_test: ')\n",
    "print(y_test[0:5])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUNOB4E1KBHz"
   },
   "source": [
    "##2. Similarity\n",
    "\n",
    "For this workshop, we will use the [Euclidean Distance] to calculate the distance between to data instances. This function will allow us to measure the distance between a training data point and a new data point(test data). \n",
    "\n",
    "[Euclidean Distance]: https://en.wikipedia.org/wiki/Euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdT3eawDKAOW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# input: Two arrays of the same length containing measurements. \n",
    "# output: The distance between the two arrays\n",
    "\n",
    "def euclidean_distance(train_data, new_data): \n",
    "  # check that two arrays are of the same length\n",
    "  if len(train_data) != len(new_data): \n",
    "    print('ERROR:Data Length Mismatch')\n",
    "    return()\n",
    "   \n",
    "  distance = 0\n",
    "  for i in range(0,len(train_data)):\n",
    "    distance += (train_data[i] - new_data[i]) ** 2\n",
    "    \n",
    "  return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsGX0LmGNXVl"
   },
   "source": [
    "##3. Neighbors\n",
    "Now that we have a function that calculates the distance between two points, we can get calculate distance between our training data and new data point. We then want to find the k minimum distances and the label of the corresponding training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzgpns6INWRj"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "#input: \n",
    "# train_data - a 2d-array containing the training data\n",
    "# train_labels - the labels for the training data\n",
    "# new_data - the data that is to be classfied \n",
    "# k - the number of neighbors to return\n",
    "\n",
    "# output: a list of k labels of the nearest neighbors\n",
    "\n",
    "def nearest_neighbors(train_data, train_labels, new_data, k):\n",
    "  distances_list = []\n",
    "  \n",
    "  # iterate through the training data\n",
    "  for i in range(0, len(train_data)):\n",
    "    # get the distance between one point of the training data and the new data\n",
    "    distance = euclidean_distance(train_data[i], new_data)\n",
    "    \n",
    "    # append a tuple containing the label and the distance to the list\n",
    "    distances_list.append((train_labels[i],distance))\n",
    "    \n",
    "  # sort the list by the distance by ascending order\n",
    "  distances_list = sorted(distances_list,key=operator.itemgetter(1))\n",
    "  \n",
    "  # return the first k elements of sorted list\n",
    "  return distances_list[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "nqpddZMYVD5E",
    "outputId": "0a66f781-c250-4a37-a640-50f7d882cabb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3.7416573867739413)]\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2,3,4],[2,3,4,5]]\n",
    "labels = [0,1]\n",
    "new_data = [1,1,1,1]\n",
    "k = 1\n",
    "\n",
    "neighbors = nearest_neighbors(data,labels,new_data,k)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4oTJbWiS9Fp"
   },
   "source": [
    "## 4. Response\n",
    "Now that we have the k minimum distances and their corresponding label, we can formulate a response for each point of our test data by finding the label that appears most often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7epm1_ITkUn"
   },
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "k = 1\n",
    "\n",
    "# iterate through the test data\n",
    "for i in range(0, len(X_test)):\n",
    "  # get the k nearest neighbors for the current test data array\n",
    "  neighbors = nearest_neighbors(X_train, y_train, X_test[i], k)\n",
    "  \n",
    "  # dictionary that keeps track of how many times a label appears\n",
    "  response_dictionary = {}\n",
    "  \n",
    "  # iterate through the k nearest neighbors\n",
    "  for neighbor in neighbors: \n",
    "    label = neighbor[0]\n",
    "    \n",
    "    # if the label exists in the dictionary then increment\n",
    "    if label in response_dictionary: \n",
    "      response_dictionary[label] += 1\n",
    "      \n",
    "    # otherwise insert label into dictionary\n",
    "    else: \n",
    "      response_dictionary.update({label:1})\n",
    "  \n",
    "  max_label = None\n",
    "  max_count = -1\n",
    "  \n",
    "  # find label that appeared most often by iterating through the dictionary\n",
    "  for key,value in response_dictionary.items(): \n",
    "    \n",
    "    # check if there is a tie\n",
    "    if value == max_count and max_label != key: \n",
    "      print('max_count: ' + str(max_count))\n",
    "      print('max_label: ' + str(max_label))\n",
    "      print('value: ' + str(value))\n",
    "      print('key: ' + str(key))\n",
    "      print('Tie: Change value of k')\n",
    "      break\n",
    "      \n",
    "    if value > max_count: \n",
    "      max_count = value\n",
    "      max_label = key\n",
    "  \n",
    "  \n",
    "  predicted = max_label\n",
    "  \n",
    "  predicted_labels.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "J6FHKesmT9B-",
    "outputId": "bd50f705-ea42-4aad-facb-95787d79315e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19LoyfH1aCks"
   },
   "source": [
    "##5. Accuracy\n",
    "Now that we have our predicted labels, we can check how many of them were correct and get a accuract percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pz1XAJb9aBxL"
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "total_count   = 0\n",
    "\n",
    "for i in range(0, len(y_test)): \n",
    "  if y_test[i] == predicted_labels[i]:\n",
    "    correct_count += 1\n",
    "  total_count += 1\n",
    "accuracy = correct_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "l0SJ_ozWVMq9",
    "outputId": "e3fe119d-8727-4bf8-fe18-51fce722ce02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXz8yLjCV8uL"
   },
   "source": [
    "##6. Main\n",
    "Now that we have all of our pieces, we can put it all together into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_u0EqiHWM8A"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(train_data, new_data): \n",
    "  # check that two arrays are of the same length\n",
    "  if len(train_data) != len(new_data): \n",
    "    print('ERROR:Data Length Mismatch')\n",
    "    return()\n",
    "\n",
    "  distance = 0\n",
    "  for i in range(0,len(train_data)):\n",
    "    distance += (train_data[i] - new_data[i]) ** 2\n",
    "\n",
    "  return math.sqrt(distance)\n",
    "\n",
    "def nearest_neighbors(train_data, train_labels, new_data, k):\n",
    "  distances_list = []\n",
    "  \n",
    "  for i in range(0, len(train_data)):\n",
    "    distance = euclidean_distance(train_data[i], new_data)\n",
    "    \n",
    "    distances_list.append((train_labels[i],distance))\n",
    "    \n",
    "  distances_list = sorted(distances_list,key=operator.itemgetter(1))\n",
    "  \n",
    "  return distances_list[:k]\n",
    "\n",
    "class KNN: \n",
    "  def __init__(self,k): \n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "    self.k_value = k\n",
    "    \n",
    "  def fit(self,train,labels): \n",
    "    self.train_data = train\n",
    "    self.train_labels = labels\n",
    "    \n",
    "  def predict(self,test_data): \n",
    "    predicted_labels = []\n",
    "    \n",
    "    for i in range(0, len(test_data)):\n",
    "      neighbors = nearest_neighbors(self.train_data, self.train_labels, test_data[i], self.k_value)\n",
    "\n",
    "      response_dictionary = {}\n",
    "\n",
    "      for neighbor in neighbors: \n",
    "        label = neighbor[0]\n",
    "\n",
    "        if label in response_dictionary: \n",
    "          response_dictionary[label] += 1\n",
    "\n",
    "        else: \n",
    "          response_dictionary.update({label:1})\n",
    "\n",
    "      max_label = None\n",
    "      max_count = -1\n",
    "\n",
    "      for key,value in response_dictionary.items(): \n",
    "\n",
    "        if value == max_count: \n",
    "          print('max_count: ' + str(max_count))\n",
    "          print('max_label: ' + str(max_label))\n",
    "          print('value: ' + str(value))\n",
    "          print('key: ' + str(key))\n",
    "          print('Tie: Change value of k')\n",
    "          return\n",
    "\n",
    "        if value > max_count: \n",
    "          max_count = value\n",
    "          max_label = key\n",
    "\n",
    "\n",
    "      predicted = max_label\n",
    "\n",
    "      predicted_labels.append(predicted)\n",
    "      \n",
    "    return predicted_labels\n",
    "  \n",
    "  def score(self,test_data, test_labels): \n",
    "    predict = self.predict(test_data)\n",
    "    \n",
    "    correct_count = 0\n",
    "    total_count   = 0\n",
    "\n",
    "    for i in range(0, len(test_labels)): \n",
    "      if test_labels[i] == predict[i]:\n",
    "        correct_count += 1\n",
    "      total_count += 1\n",
    "      \n",
    "    accuracy = correct_count/total_count\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWYBuRp3azMi"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sdh_tGmbYogf"
   },
   "outputs": [],
   "source": [
    "knn = KNN(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD0d-kIkY9ji"
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "UqxUBkuyZEnq",
    "outputId": "f479a6bd-eb11-4b0b-ed35-fc1ce1ecc989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "predict = knn.predict(X_test)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "BlPk5aMeaD03",
    "outputId": "df4d2060-a77d-425e-f7bc-8b29d1939b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "score = knn.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7sKMwhlPg6ZA"
   },
   "source": [
    "##8. Using sklearn's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "SnhCB4RWausx",
    "outputId": "1ab9fe5e-86bb-4f1b-9904-1b4065222914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(knn.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "week13_knn_completed",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
