{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_6_intro_to_webscrapping_workshop.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "faCDglr2QtxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![ADSA Logo](http://i.imgur.com/BV0CdHZ.png?2 \"ADSA Logo\")"
      ]
    },
    {
      "metadata": {
        "id": "N577Ay9mQtxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Spring 2019 ADSA Workshop - Introduction to Web Scraping\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "t9MgAzEyl_Wv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##What is webscraping? \n",
        "Web \"scraping\" (also called \"web harvesting\", \"web data extraction\" or even \"web data mining\"), can be defined as \"the construction of an agent to download, parse, and organize data from the web in an automated manner\""
      ]
    },
    {
      "metadata": {
        "id": "HzEC5cb9Qt0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Using `urllib` to Access Web Data and `BeautifulSoup` to Parse it.\n",
        "\n",
        "`urllib` is a very easy-to-use module to fetch URLs (Uniform Resource Locators). You can use this module to easily read and use web content in your code. We are going to use this module to build an app that gets weather data.\n",
        "\n",
        "`BeautifulSoup` on the other hand is HTML and XML parser. It creates a parse tree from the parsed webpage and can be used to access several tags in the HTML page. This makes it a very useful tool for web-scraping.\n",
        "\n",
        "Let's start by seeing what reading the Python.org homepage through `urllib` looks like. Then we will use `BeautifulSoup` to print all the links present in the webpage!   \n",
        "For more information visit: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
      ]
    },
    {
      "metadata": {
        "id": "H35SYNczQt0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "093dcca6-fe46-4e97-fb9e-d51f511e8b18"
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "url = 'http://python.org'\n",
        "response = urlopen(url) \n",
        "html = response.read()\n",
        "\n",
        "# We can use BeautifulSoup to parse the web tree to give us only the web-links instead.\n",
        "soup = BeautifulSoup(html, \"html.parser\") #Create a soup object. Check its class using:  print type(soup)\n",
        "print(type(soup))\n",
        "#print(soup.prettify())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'bs4.BeautifulSoup'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAvEee07Pyfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1106
        },
        "outputId": "93a9d8ca-9abb-4498-b52f-2053f2ed9fa7"
      },
      "cell_type": "code",
      "source": [
        "for link in soup.find_all('a', href=True): #Finding all the tags containing 'a' and its a link\n",
        "    if \"http\" in link['href']:\n",
        "        print(link['href'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://docs.python.org\n",
            "https://pypi.python.org/\n",
            "http://plus.google.com/+Python\n",
            "http://www.facebook.com/pythonlang?fref=ts\n",
            "http://twitter.com/ThePSF\n",
            "http://brochure.getpython.info/\n",
            "https://docs.python.org/3/license.html\n",
            "https://wiki.python.org/moin/BeginnersGuide\n",
            "https://devguide.python.org/\n",
            "https://docs.python.org/faq/\n",
            "http://wiki.python.org/moin/Languages\n",
            "http://python.org/dev/peps/\n",
            "https://wiki.python.org/moin/PythonBooks\n",
            "https://wiki.python.org/moin/\n",
            "https://www.python.org/psf/codeofconduct/\n",
            "http://planetpython.org/\n",
            "http://pyfound.blogspot.com/\n",
            "http://pycon.blogspot.com/\n",
            "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
            "http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
            "https://docs.python.org\n",
            "http://blog.python.org\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/4U66sA2wtWw/python-371rc1-and-367rc1-now-available.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/5EA0ClmtbD8/python-356-and-python-349-are-now.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/RMqgTQsV720/python-3.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/PuHgTVhNAAE/python-370rc1-and-366rc1-now-available.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/rPQiRIs2Qhg/python-370b5-bonus-beta-is-now.html\n",
            "http://www.djangoproject.com/\n",
            "http://www.pylonsproject.org/\n",
            "http://bottlepy.org\n",
            "http://tornadoweb.org\n",
            "http://flask.pocoo.org/\n",
            "http://www.web2py.com/\n",
            "http://wiki.python.org/moin/TkInter\n",
            "https://wiki.gnome.org/Projects/PyGObject\n",
            "http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
            "https://wiki.qt.io/PySide\n",
            "https://kivy.org/\n",
            "http://www.wxpython.org/\n",
            "http://www.scipy.org\n",
            "http://pandas.pydata.org/\n",
            "http://ipython.org\n",
            "http://buildbot.net/\n",
            "http://trac.edgewall.org/\n",
            "http://roundup.sourceforge.net/\n",
            "http://www.ansible.com\n",
            "http://www.saltstack.com\n",
            "https://www.openstack.org\n",
            "http://brochure.getpython.info/\n",
            "https://docs.python.org/3/license.html\n",
            "https://wiki.python.org/moin/BeginnersGuide\n",
            "https://devguide.python.org/\n",
            "https://docs.python.org/faq/\n",
            "http://wiki.python.org/moin/Languages\n",
            "http://python.org/dev/peps/\n",
            "https://wiki.python.org/moin/PythonBooks\n",
            "https://wiki.python.org/moin/\n",
            "https://www.python.org/psf/codeofconduct/\n",
            "http://planetpython.org/\n",
            "http://pyfound.blogspot.com/\n",
            "http://pycon.blogspot.com/\n",
            "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
            "https://devguide.python.org/\n",
            "https://bugs.python.org/\n",
            "https://mail.python.org/mailman/listinfo/python-dev\n",
            "https://github.com/python/pythondotorg/issues\n",
            "https://status.python.org/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMbUWLo3Qt0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This prints out the complete source HTML of the website. We have this data stored as a regular string in the html variable, and we can now do whatever we want with it.\n",
        "\n",
        "### Build a Weather Reporting Program!"
      ]
    },
    {
      "metadata": {
        "id": "KiQPZVo8Qt0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now use the `urllib` module to build a small program that tells you the city and the current weather when you give it the zip code of a place.\n",
        "For the weather data, we will use the service OpenWeatherMap.org. Copy the URL http://api.openweathermap.org/data/2.5/weather?zip=61820,us&appid=cf7f4e0a615b5f48f4601377a2c98a75 into the address bar in a new tab. The website shows text about the weather information in the area of zipcode 61820 (Champaign). Let's load this information through `urllib`."
      ]
    },
    {
      "metadata": {
        "id": "VmA9mrdbQt0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "579d52f0-6a61-47c2-9414-981d4bea595a"
      },
      "cell_type": "code",
      "source": [
        "appid = 'cf7f4e0a615b5f48f4601377a2c98a75'\n",
        "zipcode = '61820'\n",
        "url = 'http://api.openweathermap.org/data/2.5/weather?zip={},us&APPID={}'.format(zipcode, appid)\n",
        "response = urlopen(url)\n",
        "weather_html = response.read().decode('utf-8')\n",
        "\n",
        "print(weather_html)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"coord\":{\"lon\":-88.24,\"lat\":40.12},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"base\":\"stations\",\"main\":{\"temp\":296.31,\"pressure\":1020,\"humidity\":80,\"temp_min\":294.05,\"temp_max\":299.05},\"visibility\":16093,\"wind\":{\"speed\":1.46,\"deg\":108.513},\"clouds\":{\"all\":1},\"dt\":1538933700,\"sys\":{\"type\":1,\"id\":968,\"message\":0.0044,\"country\":\"US\",\"sunrise\":1538913364,\"sunset\":1538954660},\"id\":420012386,\"name\":\"Bloomington\",\"cod\":200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_0sA47vQt0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The string that we have received is formatted in JSON, which is very similar to a Python dictionary. Let's parse this JSON data into a Python dictionary, and also pretty print it so that we can understand the structure of the data."
      ]
    },
    {
      "metadata": {
        "id": "3JYM44P4Qt0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "f4213a66-62a1-4405-e788-7e738afc2e62"
      },
      "cell_type": "code",
      "source": [
        "from json import JSONDecoder, dumps\n",
        "\n",
        "decoder = JSONDecoder()\n",
        "weather_data = decoder.decode(weather_html)\n",
        "pretty_weather_data = dumps(weather_data, indent=2, separators=(',', ': '))\n",
        "\n",
        "print(pretty_weather_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"coord\": {\n",
            "    \"lon\": -88.24,\n",
            "    \"lat\": 40.12\n",
            "  },\n",
            "  \"weather\": [\n",
            "    {\n",
            "      \"id\": 800,\n",
            "      \"main\": \"Clear\",\n",
            "      \"description\": \"clear sky\",\n",
            "      \"icon\": \"01d\"\n",
            "    }\n",
            "  ],\n",
            "  \"base\": \"stations\",\n",
            "  \"main\": {\n",
            "    \"temp\": 296.31,\n",
            "    \"pressure\": 1020,\n",
            "    \"humidity\": 80,\n",
            "    \"temp_min\": 294.05,\n",
            "    \"temp_max\": 299.05\n",
            "  },\n",
            "  \"visibility\": 16093,\n",
            "  \"wind\": {\n",
            "    \"speed\": 1.46,\n",
            "    \"deg\": 108.513\n",
            "  },\n",
            "  \"clouds\": {\n",
            "    \"all\": 1\n",
            "  },\n",
            "  \"dt\": 1538933700,\n",
            "  \"sys\": {\n",
            "    \"type\": 1,\n",
            "    \"id\": 968,\n",
            "    \"message\": 0.0044,\n",
            "    \"country\": \"US\",\n",
            "    \"sunrise\": 1538913364,\n",
            "    \"sunset\": 1538954660\n",
            "  },\n",
            "  \"id\": 420012386,\n",
            "  \"name\": \"Bloomington\",\n",
            "  \"cod\": 200\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6OhnY_zMQt0Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The information we want to build our program is the name field and the temp field which is inside the main sub-dictionary."
      ]
    },
    {
      "metadata": {
        "id": "NBg4Ko6bQt0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c3b7469c-0643-4d55-aa80-ad58cf2f1ea7"
      },
      "cell_type": "code",
      "source": [
        "city = weather_data['name']\n",
        "\n",
        "temp_kelvin = weather_data['main']['temp']\n",
        "temp_fah = 1.8 * (temp_kelvin - 273.15) + 32\n",
        "\n",
        "print(\"We are in {0} and it is {1} degrees outside!\".format(city, temp_fah))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are in Bloomington and it is 73.68800000000005 degrees outside!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WNPiNpYTQt0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's put all of this into a nice and easy to use function."
      ]
    },
    {
      "metadata": {
        "id": "J99G9h7GQt0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tell_me_weather(zipcode):\n",
        "    # import urllib\n",
        "    appid = 'cf7f4e0a615b5f48f4601377a2c98a75'\n",
        "    url = 'http://api.openweathermap.org/data/2.5/weather?zip={0},us&APPID={1}'.format(zipcode, appid)\n",
        "    response = urlopen(url)\n",
        "    weather_html = response.read().decode('utf-8')\n",
        "\n",
        "    decoder = JSONDecoder()\n",
        "    weather_data = decoder.decode(weather_html)\n",
        "    city = weather_data['name']\n",
        "\n",
        "    temp_kelvin = weather_data['main']['temp']\n",
        "    temp_fah = 1.8 * (temp_kelvin - 273.15) + 32\n",
        "\n",
        "    print(\"You are in {0} and it is {1} degrees outside!\".format(city, temp_fah))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_UnqYoeQt0g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's use our new tell_me_weather function!"
      ]
    },
    {
      "metadata": {
        "id": "q1dDN8epQt0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "12b4d1cc-d927-48eb-e2b2-8a41764c8f76"
      },
      "cell_type": "code",
      "source": [
        "tell_me_weather(61801)\n",
        "tell_me_weather(60601)\n",
        "tell_me_weather(94102)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are in Bloomington and it is 75.93800000000005 degrees outside!\n",
            "You are in Chicago and it is 59.57600000000009 degrees outside!\n",
            "You are in San Francisco and it is 72.46400000000003 degrees outside!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3j3o6jyYZXO3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Excercise \n",
        "Scrape all of the thread titles from the first page reddit posts. \n",
        "Hints: \n",
        "1) Use \"inspect\" function on the page to find the correct tag. Use this tag with the \"find_all\" function to get each of the titles. "
      ]
    },
    {
      "metadata": {
        "id": "YydMGkHJZsSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://www.reddit.com/r/worldnews/hot/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GFD_e01_jddq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now find the the number the comments that each of the reddit threads has received. \n",
        "\n",
        "Hints: There are some threads that are promotions. "
      ]
    },
    {
      "metadata": {
        "id": "hZhE340x0O8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iFaP-J2IlPsV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now create a dataframe with your title and comment count. The columns should be named \"title\" and \"comment_count\""
      ]
    },
    {
      "metadata": {
        "id": "nW9aKUcl0O3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}