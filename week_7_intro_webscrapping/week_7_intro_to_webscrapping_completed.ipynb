{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_6_intro_to_webscrapping_completed.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "faCDglr2QtxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![ADSA Logo](http://i.imgur.com/BV0CdHZ.png?2 \"ADSA Logo\")"
      ]
    },
    {
      "metadata": {
        "id": "N577Ay9mQtxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Spring 2019 ADSA Workshop - Introduction to Web Scraping\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "t9MgAzEyl_Wv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##What is webscraping? \n",
        "Web \"scraping\" (also called \"web harvesting\", \"web data extraction\" or even \"web data mining\"), can be defined as \"the construction of an agent to download, parse, and organize data from the web in an automated manner\""
      ]
    },
    {
      "metadata": {
        "id": "HzEC5cb9Qt0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Using `urllib` to Access Web Data and `BeautifulSoup` to Parse it.\n",
        "\n",
        "`urllib` is a very easy-to-use module to fetch URLs (Uniform Resource Locators). You can use this module to easily read and use web content in your code. We are going to use this module to build an app that gets weather data.\n",
        "\n",
        "`BeautifulSoup` on the other hand is HTML and XML parser. It creates a parse tree from the parsed webpage and can be used to access several tags in the HTML page. This makes it a very useful tool for web-scraping.\n",
        "\n",
        "Let's start by seeing what reading the Python.org homepage through `urllib` looks like. Then we will use `BeautifulSoup` to print all the links present in the webpage!   \n",
        "For more information visit: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
      ]
    },
    {
      "metadata": {
        "id": "H35SYNczQt0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b97a20e9-01ac-4bde-f965-70c2e45f23fc"
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "url = 'http://python.org'\n",
        "response = urlopen(url) \n",
        "html = response.read()\n",
        "\n",
        "# We can use BeautifulSoup to parse the web tree to give us only the web-links instead.\n",
        "soup = BeautifulSoup(html, \"html.parser\") #Create a soup object. Check its class using:  print type(soup)\n",
        "print(type(soup))\n",
        "#print(soup.prettify())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'bs4.BeautifulSoup'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAvEee07Pyfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1106
        },
        "outputId": "48c0a804-4a34-4b45-b474-59c10f00c2d1"
      },
      "cell_type": "code",
      "source": [
        "for link in soup.find_all('a', href=True): #Finding all the tags containing 'a' and its a link\n",
        "    if \"http\" in link['href']:\n",
        "        print(link['href'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://docs.python.org\n",
            "https://pypi.python.org/\n",
            "http://plus.google.com/+Python\n",
            "http://www.facebook.com/pythonlang?fref=ts\n",
            "http://twitter.com/ThePSF\n",
            "http://brochure.getpython.info/\n",
            "https://docs.python.org/3/license.html\n",
            "https://wiki.python.org/moin/BeginnersGuide\n",
            "https://devguide.python.org/\n",
            "https://docs.python.org/faq/\n",
            "http://wiki.python.org/moin/Languages\n",
            "http://python.org/dev/peps/\n",
            "https://wiki.python.org/moin/PythonBooks\n",
            "https://wiki.python.org/moin/\n",
            "https://www.python.org/psf/codeofconduct/\n",
            "http://planetpython.org/\n",
            "http://pyfound.blogspot.com/\n",
            "http://pycon.blogspot.com/\n",
            "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
            "http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
            "https://docs.python.org\n",
            "http://blog.python.org\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/4U66sA2wtWw/python-371rc1-and-367rc1-now-available.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/5EA0ClmtbD8/python-356-and-python-349-are-now.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/RMqgTQsV720/python-3.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/PuHgTVhNAAE/python-370rc1-and-366rc1-now-available.html\n",
            "http://feedproxy.google.com/~r/PythonInsider/~3/rPQiRIs2Qhg/python-370b5-bonus-beta-is-now.html\n",
            "http://www.djangoproject.com/\n",
            "http://www.pylonsproject.org/\n",
            "http://bottlepy.org\n",
            "http://tornadoweb.org\n",
            "http://flask.pocoo.org/\n",
            "http://www.web2py.com/\n",
            "http://wiki.python.org/moin/TkInter\n",
            "https://wiki.gnome.org/Projects/PyGObject\n",
            "http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
            "https://wiki.qt.io/PySide\n",
            "https://kivy.org/\n",
            "http://www.wxpython.org/\n",
            "http://www.scipy.org\n",
            "http://pandas.pydata.org/\n",
            "http://ipython.org\n",
            "http://buildbot.net/\n",
            "http://trac.edgewall.org/\n",
            "http://roundup.sourceforge.net/\n",
            "http://www.ansible.com\n",
            "http://www.saltstack.com\n",
            "https://www.openstack.org\n",
            "http://brochure.getpython.info/\n",
            "https://docs.python.org/3/license.html\n",
            "https://wiki.python.org/moin/BeginnersGuide\n",
            "https://devguide.python.org/\n",
            "https://docs.python.org/faq/\n",
            "http://wiki.python.org/moin/Languages\n",
            "http://python.org/dev/peps/\n",
            "https://wiki.python.org/moin/PythonBooks\n",
            "https://wiki.python.org/moin/\n",
            "https://www.python.org/psf/codeofconduct/\n",
            "http://planetpython.org/\n",
            "http://pyfound.blogspot.com/\n",
            "http://pycon.blogspot.com/\n",
            "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
            "https://devguide.python.org/\n",
            "https://bugs.python.org/\n",
            "https://mail.python.org/mailman/listinfo/python-dev\n",
            "https://github.com/python/pythondotorg/issues\n",
            "https://status.python.org/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMbUWLo3Qt0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This prints out the complete source HTML of the website. We have this data stored as a regular string in the html variable, and we can now do whatever we want with it.\n",
        "\n",
        "### Build a Weather Reporting Program!"
      ]
    },
    {
      "metadata": {
        "id": "KiQPZVo8Qt0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now use the `urllib` module to build a small program that tells you the city and the current weather when you give it the zip code of a place.\n",
        "For the weather data, we will use the service OpenWeatherMap.org. Copy the URL http://api.openweathermap.org/data/2.5/weather?zip=61820,us&appid=cf7f4e0a615b5f48f4601377a2c98a75 into the address bar in a new tab. The website shows text about the weather information in the area of zipcode 61820 (Champaign). Let's load this information through `urllib`."
      ]
    },
    {
      "metadata": {
        "id": "VmA9mrdbQt0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "726755f7-89e4-4ab8-e9de-322fcc84a66b"
      },
      "cell_type": "code",
      "source": [
        "appid = 'cf7f4e0a615b5f48f4601377a2c98a75'\n",
        "zipcode = '61820'\n",
        "url = 'http://api.openweathermap.org/data/2.5/weather?zip={},us&APPID={}'.format(zipcode, appid)\n",
        "response = urlopen(url)\n",
        "weather_html = response.read().decode('utf-8')\n",
        "\n",
        "print(weather_html)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"coord\":{\"lon\":-88.24,\"lat\":40.12},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"base\":\"stations\",\"main\":{\"temp\":296.02,\"pressure\":1021,\"humidity\":78,\"temp_min\":294.05,\"temp_max\":299.05},\"visibility\":16093,\"wind\":{\"speed\":1.5,\"deg\":130},\"clouds\":{\"all\":75},\"dt\":1538932680,\"sys\":{\"type\":1,\"id\":960,\"message\":0.0136,\"country\":\"US\",\"sunrise\":1538913364,\"sunset\":1538954661},\"id\":420012386,\"name\":\"Bloomington\",\"cod\":200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_0sA47vQt0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The string that we have received is formatted in JSON, which is very similar to a Python dictionary. Let's parse this JSON data into a Python dictionary, and also pretty print it so that we can understand the structure of the data."
      ]
    },
    {
      "metadata": {
        "id": "3JYM44P4Qt0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "fa519690-5bbc-49cd-b40e-bad14346cf1f"
      },
      "cell_type": "code",
      "source": [
        "from json import JSONDecoder, dumps\n",
        "\n",
        "decoder = JSONDecoder()\n",
        "weather_data = decoder.decode(weather_html)\n",
        "pretty_weather_data = dumps(weather_data, indent=2, separators=(',', ': '))\n",
        "\n",
        "print(pretty_weather_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"coord\": {\n",
            "    \"lon\": -88.24,\n",
            "    \"lat\": 40.12\n",
            "  },\n",
            "  \"weather\": [\n",
            "    {\n",
            "      \"id\": 803,\n",
            "      \"main\": \"Clouds\",\n",
            "      \"description\": \"broken clouds\",\n",
            "      \"icon\": \"04d\"\n",
            "    }\n",
            "  ],\n",
            "  \"base\": \"stations\",\n",
            "  \"main\": {\n",
            "    \"temp\": 296.02,\n",
            "    \"pressure\": 1021,\n",
            "    \"humidity\": 78,\n",
            "    \"temp_min\": 294.05,\n",
            "    \"temp_max\": 299.05\n",
            "  },\n",
            "  \"visibility\": 16093,\n",
            "  \"wind\": {\n",
            "    \"speed\": 1.5,\n",
            "    \"deg\": 130\n",
            "  },\n",
            "  \"clouds\": {\n",
            "    \"all\": 75\n",
            "  },\n",
            "  \"dt\": 1538932680,\n",
            "  \"sys\": {\n",
            "    \"type\": 1,\n",
            "    \"id\": 960,\n",
            "    \"message\": 0.0136,\n",
            "    \"country\": \"US\",\n",
            "    \"sunrise\": 1538913364,\n",
            "    \"sunset\": 1538954661\n",
            "  },\n",
            "  \"id\": 420012386,\n",
            "  \"name\": \"Bloomington\",\n",
            "  \"cod\": 200\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6OhnY_zMQt0Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The information we want to build our program is the name field and the temp field which is inside the main sub-dictionary."
      ]
    },
    {
      "metadata": {
        "id": "NBg4Ko6bQt0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "617b7882-370b-4f9a-d88f-223edca70291"
      },
      "cell_type": "code",
      "source": [
        "city = weather_data['name']\n",
        "\n",
        "temp_kelvin = weather_data['main']['temp']\n",
        "temp_fah = 1.8 * (temp_kelvin - 273.15) + 32\n",
        "\n",
        "print(\"We are in {0} and it is {1} degrees outside!\".format(city, temp_fah))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are in Bloomington and it is 73.16600000000001 degrees outside!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WNPiNpYTQt0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's put all of this into a nice and easy to use function."
      ]
    },
    {
      "metadata": {
        "id": "J99G9h7GQt0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tell_me_weather(zipcode):\n",
        "    # import urllib\n",
        "    appid = 'cf7f4e0a615b5f48f4601377a2c98a75'\n",
        "    url = 'http://api.openweathermap.org/data/2.5/weather?zip={0},us&APPID={1}'.format(zipcode, appid)\n",
        "    response = urlopen(url)\n",
        "    weather_html = response.read().decode('utf-8')\n",
        "\n",
        "    decoder = JSONDecoder()\n",
        "    weather_data = decoder.decode(weather_html)\n",
        "    city = weather_data['name']\n",
        "\n",
        "    temp_kelvin = weather_data['main']['temp']\n",
        "    temp_fah = 1.8 * (temp_kelvin - 273.15) + 32\n",
        "\n",
        "    print(\"You are in {0} and it is {1} degrees outside!\".format(city, temp_fah))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_UnqYoeQt0g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's use our new tell_me_weather function!"
      ]
    },
    {
      "metadata": {
        "id": "q1dDN8epQt0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "7e093596-e2dd-4e9c-d516-2421785692e0"
      },
      "cell_type": "code",
      "source": [
        "tell_me_weather(61801)\n",
        "tell_me_weather(60601)\n",
        "tell_me_weather(94102)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are in Bloomington and it is 73.83200000000002 degrees outside!\n",
            "You are in Chicago and it is 59.522000000000034 degrees outside!\n",
            "You are in San Francisco and it is 71.78000000000004 degrees outside!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3j3o6jyYZXO3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Excercise \n",
        "Scrape all of the thread titles from the first page reddit posts. \n",
        "Hints: \n",
        "1) Use \"inspect\" function on the page to find the correct tag. Use this tag with the \"find_all\" function to get each of the titles. "
      ]
    },
    {
      "metadata": {
        "id": "YydMGkHJZsSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://www.reddit.com/r/worldnews/hot/'\n",
        "response = urlopen(url)\n",
        "reddit_html = response.read().decode('utf-8')\n",
        "\n",
        "soup = BeautifulSoup(reddit_html, \"html.parser\")\n",
        "#print(soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhE9Q6_eaJP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "42076077-0716-4ab1-c3f9-7e21c4597709"
      },
      "cell_type": "code",
      "source": [
        "title_list = []                # append your thread titles here\n",
        "posts = soup.find_all('h2')    # find all of the h2 tags on the the page\n",
        "for post in posts:             # iterate through each of the h2 tags\n",
        "  print(post.text)\n",
        "  title_list.append(post.text) # append the text portion to the list\n",
        "print(len(title_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wife of Israeli prime minister goes on trial for fraud\n",
            "A peptide from an Australian funnel-web spider has been found to kill both human melanoma cells and cancerous Tasmania devil facial tumours that are threatening the survival of the species\n",
            "Christian woman on death row in Pakistan for insulting Prophet Muhammad to make final court appeal\n",
            "Pilot shot in helicopter crash which killed senior Putin prosecutor\n",
            "Hey Reddit: Want to write better? Eliminate grammatical mistakes, wipe out wordiness, and let your ideas shine. See for yourself why over 10 million users are hooked on Grammarly's free writing app.\n",
            "Man who wanted country 'cleansed of white people' found guilty of hate speech\n",
            "Banksy art \"doubles in value\" after shredding itself during auction\n",
            "Costa Rica Surpasses 98% of Clean Energy Generation for Fourth Year in a Row\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GFD_e01_jddq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now find the the number the comments that each of the reddit threads has received. \n",
        "\n",
        "Hints: There are some threads that are promotions. "
      ]
    },
    {
      "metadata": {
        "id": "hZhE340x0O8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "comment_list = []               # append your comment counts here\n",
        "posts = soup.body.find_all('a') # find all of the a tags on the page\n",
        "for post in posts:              # iterate through each of the a tags\n",
        "  if 'comment' in post.text:    # check if the string comment is in the text portion\n",
        "    comment_list.append(post.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGs8bui-kcxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fdbf9ec4-d444-475f-daae-ada793aaf411"
      },
      "cell_type": "code",
      "source": [
        "for i in range(0,len(comment_list)): # iterate through you comment counts\n",
        "  if comment_list[i] == 'comment':   # if the string is comment, then it is from a promotional thread\n",
        "    comment_list[i] = '0'            # set it to zero\n",
        "  else:\n",
        "    comment_list[i] = comment_list[i][:-len('comments')-1] #otherwise, just extract the number portion\n",
        "print(comment_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['668', '134', '705', '113', '0', '3.9k', '208', '557']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iFaP-J2IlPsV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now create a dataframe with your title and comment count. The columns should be named \"title\" and \"comment_count\""
      ]
    },
    {
      "metadata": {
        "id": "nW9aKUcl0O3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "9f48909c-b989-4c80-c8ca-c00f2fbf8ea7"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_reddit_post = pd.DataFrame(columns = ['title', \"comment_count\"]) # initialize a dataframe\n",
        "df_reddit_post['title'] = title_list\n",
        "df_reddit_post['comment_count'] = comment_list\n",
        "print(df_reddit_post)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               title comment_count\n",
            "0  Wife of Israeli prime minister goes on trial f...           668\n",
            "1  A peptide from an Australian funnel-web spider...           134\n",
            "2  Christian woman on death row in Pakistan for i...           705\n",
            "3  Pilot shot in helicopter crash which killed se...           113\n",
            "4  Hey Reddit: Want to write better? Eliminate gr...             0\n",
            "5  Man who wanted country 'cleansed of white peop...          3.9k\n",
            "6  Banksy art \"doubles in value\" after shredding ...           208\n",
            "7  Costa Rica Surpasses 98% of Clean Energy Gener...           557\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}